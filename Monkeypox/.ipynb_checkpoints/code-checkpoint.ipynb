{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b7ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed20907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chickenpox', 'Measles', 'Monkeypox', 'Normal']\n",
      "{'Chickenpox': 0, 'Measles': 1, 'Monkeypox': 2, 'Normal': 3}\n"
     ]
    }
   ],
   "source": [
    "root = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/Data/'\n",
    "\n",
    "data_transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                     transforms.Resize((64,64)),\n",
    "                                     transforms.ToTensor()])\n",
    "dataset = ImageFolder(root, transform=data_transform)\n",
    "\n",
    "print(dataset.classes)\n",
    "print(dataset.class_to_idx)\n",
    "\n",
    "# Split test and train dataset \n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Set batch size of train data loader\n",
    "batch_size_train = 20\n",
    "\n",
    "# Set batch size of test data loader\n",
    "batch_size_test = 22\n",
    "\n",
    "# load the split train and test data into batches via DataLoader()\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "label_map={\n",
    "    0:\"Chickenpox\",\n",
    "    1:\"Measles\",\n",
    "    2:\"Monkeypox\",\n",
    "    3:\"Normal\"\n",
    "}\n",
    "classes = ('Chickenpox', 'Measles', 'Monkeypox', 'Normal')\n",
    "\n",
    "dataloaders={}\n",
    "dataloaders[\"train\"]=train_loader\n",
    "dataloaders[\"val\"]=test_loader\n",
    "\n",
    "dataset_sizes = {\"train\":len(train_loader.dataset),\"val\":len(test_loader.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9c1316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normal')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    pass\n",
    "\n",
    "# Get one batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "indx=10\n",
    "plt.imshow(images[indx].reshape(64,64))\n",
    "plt.title(label_map[int(labels[indx].numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1478a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs=30\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.repeat(1, 3, 1, 1)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy(model, test_loader) :\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_corrects=0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.repeat(1, 3, 1, 1)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device) \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        acc = running_corrects.double() / dataset_sizes[\"val\"]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0771f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Counter({2: 438, 3: 422, 0: 256, 1: 216})\n",
      "Test: Counter({2: 192, 3: 163, 0: 120, 1: 97})\n",
      "Total: {0: 376, 1: 313, 2: 630, 3: 585}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_classes = [dataset.targets[i] for i in train_data.indices]\n",
    "print(\"train:\",Counter(train_classes)) # if doesn' work: Counter(i.item() for i in train_classes)\n",
    "\n",
    "test_classes = [dataset.targets[i] for i in test_data.indices]\n",
    "print(\"Test:\",Counter(test_classes)) # if doesn' work: Counter(i.item() for i in train_classes)\n",
    "\n",
    "print(\"Total:\",dict(Counter(test_data.dataset.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cdaa5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0426 Acc: 0.5638\n",
      "val Loss: 0.7784 Acc: 0.6853\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4646 Acc: 0.8123\n",
      "val Loss: 0.6014 Acc: 0.7483\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.3193 Acc: 0.8626\n",
      "val Loss: 0.5600 Acc: 0.7535\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.1781 Acc: 0.9279\n",
      "val Loss: 0.6112 Acc: 0.7587\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1445 Acc: 0.9452\n",
      "val Loss: 0.6050 Acc: 0.7710\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1015 Acc: 0.9670\n",
      "val Loss: 0.6017 Acc: 0.7885\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9662\n",
      "val Loss: 0.7239 Acc: 0.7587\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0647 Acc: 0.9835\n",
      "val Loss: 0.6301 Acc: 0.7832\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0547 Acc: 0.9865\n",
      "val Loss: 0.6334 Acc: 0.7780\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0643 Acc: 0.9820\n",
      "val Loss: 0.6479 Acc: 0.7727\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0446 Acc: 0.9895\n",
      "val Loss: 0.6127 Acc: 0.7815\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0415 Acc: 0.9910\n",
      "val Loss: 0.6519 Acc: 0.7850\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0400 Acc: 0.9917\n",
      "val Loss: 0.6381 Acc: 0.7797\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0356 Acc: 0.9940\n",
      "val Loss: 0.6305 Acc: 0.7937\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0376 Acc: 0.9887\n",
      "val Loss: 0.6303 Acc: 0.7937\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0324 Acc: 0.9955\n",
      "val Loss: 0.6544 Acc: 0.7797\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.9932\n",
      "val Loss: 0.6402 Acc: 0.7885\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9940\n",
      "val Loss: 0.6162 Acc: 0.7920\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.9955\n",
      "val Loss: 0.6643 Acc: 0.7832\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0374 Acc: 0.9925\n",
      "val Loss: 0.6451 Acc: 0.7850\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0395 Acc: 0.9902\n",
      "val Loss: 0.6543 Acc: 0.7885\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0394 Acc: 0.9947\n",
      "val Loss: 0.6391 Acc: 0.7937\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0333 Acc: 0.9970\n",
      "val Loss: 0.6622 Acc: 0.7850\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0285 Acc: 0.9970\n",
      "val Loss: 0.6522 Acc: 0.7867\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0381 Acc: 0.9902\n",
      "val Loss: 0.6520 Acc: 0.7867\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0321 Acc: 0.9947\n",
      "val Loss: 0.6545 Acc: 0.7832\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.9955\n",
      "val Loss: 0.6542 Acc: 0.8007\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0305 Acc: 0.9962\n",
      "val Loss: 0.6390 Acc: 0.7692\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0354 Acc: 0.9910\n",
      "val Loss: 0.6403 Acc: 0.7972\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0293 Acc: 0.9955\n",
      "val Loss: 0.6226 Acc: 0.7937\n",
      "\n",
      "Training complete in 13m 49s\n",
      "Best val Acc: 0.800699\n",
      "tensor(0.8007, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/resnet18_net.pth'\n",
    "\n",
    "#setup model\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# training\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load model\n",
    "model_ft3 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft3.fc.in_features\n",
    "model_ft3.fc = nn.Linear(num_ftrs, len(classes))\n",
    "model_ft3.to(device)\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test accuracy\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7404a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.2824 Acc: 0.4332\n",
      "val Loss: 1.0927 Acc: 0.4808\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.0099 Acc: 0.5526\n",
      "val Loss: 0.9830 Acc: 0.5647\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.8549 Acc: 0.6291\n",
      "val Loss: 0.9054 Acc: 0.6224\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.7222 Acc: 0.6892\n",
      "val Loss: 0.9580 Acc: 0.5769\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.6267 Acc: 0.7432\n",
      "val Loss: 0.7481 Acc: 0.6696\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.5724 Acc: 0.7470\n",
      "val Loss: 0.8213 Acc: 0.6311\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.4645 Acc: 0.8063\n",
      "val Loss: 0.6847 Acc: 0.6958\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.3023 Acc: 0.8739\n",
      "val Loss: 0.6709 Acc: 0.7168\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.2574 Acc: 0.8934\n",
      "val Loss: 0.6512 Acc: 0.7220\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.2384 Acc: 0.9024\n",
      "val Loss: 0.6667 Acc: 0.7185\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.2212 Acc: 0.9099\n",
      "val Loss: 0.6611 Acc: 0.7098\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.2091 Acc: 0.9249\n",
      "val Loss: 0.6498 Acc: 0.7255\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.1929 Acc: 0.9279\n",
      "val Loss: 0.6677 Acc: 0.7168\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.1844 Acc: 0.9362\n",
      "val Loss: 0.6573 Acc: 0.7220\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.9399\n",
      "val Loss: 0.6601 Acc: 0.7238\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.1698 Acc: 0.9407\n",
      "val Loss: 0.6631 Acc: 0.7238\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.1723 Acc: 0.9332\n",
      "val Loss: 0.6633 Acc: 0.7238\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.1652 Acc: 0.9497\n",
      "val Loss: 0.6653 Acc: 0.7203\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.1675 Acc: 0.9384\n",
      "val Loss: 0.6679 Acc: 0.7203\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.1680 Acc: 0.9392\n",
      "val Loss: 0.6696 Acc: 0.7220\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.1607 Acc: 0.9467\n",
      "val Loss: 0.6702 Acc: 0.7238\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.1601 Acc: 0.9482\n",
      "val Loss: 0.6702 Acc: 0.7255\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.1609 Acc: 0.9444\n",
      "val Loss: 0.6702 Acc: 0.7220\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9452\n",
      "val Loss: 0.6704 Acc: 0.7238\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.1596 Acc: 0.9512\n",
      "val Loss: 0.6704 Acc: 0.7220\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.1593 Acc: 0.9512\n",
      "val Loss: 0.6702 Acc: 0.7220\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.1587 Acc: 0.9452\n",
      "val Loss: 0.6702 Acc: 0.7203\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.1592 Acc: 0.9467\n",
      "val Loss: 0.6703 Acc: 0.7203\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.1658 Acc: 0.9422\n",
      "val Loss: 0.6703 Acc: 0.7203\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.1608 Acc: 0.9474\n",
      "val Loss: 0.6703 Acc: 0.7203\n",
      "\n",
      "Training complete in 15m 55s\n",
      "Best val Acc: 0.725524\n",
      "tensor(0.7255, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/alex_net.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.alexnet(pretrained=True,)\n",
    "model_ft.classifier[6] = nn.Linear(4096,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model_ft3 = models.alexnet(pretrained=True)\n",
    "model_ft3.classifier[6] = nn.Linear(4096,len(classes))\n",
    "model_ft3.to(device)\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3504b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.9963 Acc: 0.5758\n",
      "val Loss: 0.8728 Acc: 0.6451\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4878 Acc: 0.7890\n",
      "val Loss: 0.5871 Acc: 0.7622\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2824 Acc: 0.8941\n",
      "val Loss: 0.6163 Acc: 0.7500\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2028 Acc: 0.9294\n",
      "val Loss: 0.5749 Acc: 0.7867\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1328 Acc: 0.9520\n",
      "val Loss: 0.5602 Acc: 0.8007\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.0986 Acc: 0.9647\n",
      "val Loss: 0.5678 Acc: 0.7972\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0748 Acc: 0.9790\n",
      "val Loss: 0.6014 Acc: 0.7815\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0503 Acc: 0.9887\n",
      "val Loss: 0.5682 Acc: 0.8059\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0437 Acc: 0.9902\n",
      "val Loss: 0.5654 Acc: 0.8164\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0353 Acc: 0.9940\n",
      "val Loss: 0.5646 Acc: 0.8164\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0281 Acc: 0.9977\n",
      "val Loss: 0.5740 Acc: 0.8129\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9947\n",
      "val Loss: 0.5817 Acc: 0.8077\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9947\n",
      "val Loss: 0.5749 Acc: 0.8182\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.9940\n",
      "val Loss: 0.5702 Acc: 0.8269\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.9955\n",
      "val Loss: 0.5751 Acc: 0.8234\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0273 Acc: 0.9947\n",
      "val Loss: 0.5742 Acc: 0.8322\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 0.9985\n",
      "val Loss: 0.5800 Acc: 0.8269\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0265 Acc: 0.9955\n",
      "val Loss: 0.5849 Acc: 0.8129\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9985\n",
      "val Loss: 0.5899 Acc: 0.8147\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0270 Acc: 0.9955\n",
      "val Loss: 0.5877 Acc: 0.8147\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0190 Acc: 0.9992\n",
      "val Loss: 0.5764 Acc: 0.8182\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0206 Acc: 1.0000\n",
      "val Loss: 0.5697 Acc: 0.8217\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9940\n",
      "val Loss: 0.5863 Acc: 0.8129\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 0.9962\n",
      "val Loss: 0.5665 Acc: 0.8304\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0245 Acc: 0.9962\n",
      "val Loss: 0.5758 Acc: 0.8269\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0258 Acc: 0.9977\n",
      "val Loss: 0.5664 Acc: 0.8269\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0298 Acc: 0.9955\n",
      "val Loss: 0.5894 Acc: 0.8269\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0281 Acc: 0.9940\n",
      "val Loss: 0.5967 Acc: 0.8199\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.9962\n",
      "val Loss: 0.5835 Acc: 0.8269\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0260 Acc: 0.9940\n",
      "val Loss: 0.5731 Acc: 0.8269\n",
      "\n",
      "Training complete in 39m 25s\n",
      "Best val Acc: 0.832168\n",
      "tensor(0.8322, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/densenet201.pth'\n",
    "model_ft = models.densenet201(pretrained=True,)\n",
    "# print(model_ft.classifier)\n",
    "model_ft.classifier=nn.Linear(1920,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "model_ft3 = models.densenet201(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1920,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0664fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.4030 Acc: 0.3581\n",
      "val Loss: 1.2296 Acc: 0.4755\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.2049 Acc: 0.4827\n",
      "val Loss: 1.1060 Acc: 0.5612\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.1538 Acc: 0.5098\n",
      "val Loss: 1.0824 Acc: 0.5437\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.0582 Acc: 0.5353\n",
      "val Loss: 1.0178 Acc: 0.5594\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.9627 Acc: 0.5961\n",
      "val Loss: 0.8460 Acc: 0.6573\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.8596 Acc: 0.6284\n",
      "val Loss: 0.8022 Acc: 0.6678\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.7705 Acc: 0.6494\n",
      "val Loss: 0.7540 Acc: 0.6906\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.7102\n",
      "val Loss: 0.7057 Acc: 0.6801\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.5838 Acc: 0.7372\n",
      "val Loss: 0.6867 Acc: 0.6748\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.5530 Acc: 0.7410\n",
      "val Loss: 0.6750 Acc: 0.6766\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.5509 Acc: 0.7568\n",
      "val Loss: 0.6780 Acc: 0.6941\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.5355 Acc: 0.7688\n",
      "val Loss: 0.6457 Acc: 0.6958\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.5016 Acc: 0.7793\n",
      "val Loss: 0.6359 Acc: 0.7028\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.4851 Acc: 0.7815\n",
      "val Loss: 0.6362 Acc: 0.6993\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.4538 Acc: 0.7988\n",
      "val Loss: 0.6357 Acc: 0.7045\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.4624 Acc: 0.7973\n",
      "val Loss: 0.6331 Acc: 0.7028\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.4496 Acc: 0.8086\n",
      "val Loss: 0.6303 Acc: 0.7045\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.4646 Acc: 0.7890\n",
      "val Loss: 0.6282 Acc: 0.7063\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.4645 Acc: 0.7920\n",
      "val Loss: 0.6275 Acc: 0.7168\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.4593 Acc: 0.7965\n",
      "val Loss: 0.6275 Acc: 0.7080\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.4548 Acc: 0.7853\n",
      "val Loss: 0.6271 Acc: 0.7045\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.4529 Acc: 0.7935\n",
      "val Loss: 0.6263 Acc: 0.7045\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.4473 Acc: 0.7980\n",
      "val Loss: 0.6263 Acc: 0.7080\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.4574 Acc: 0.7920\n",
      "val Loss: 0.6271 Acc: 0.7115\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.4358 Acc: 0.7988\n",
      "val Loss: 0.6266 Acc: 0.7115\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.4536 Acc: 0.7965\n",
      "val Loss: 0.6273 Acc: 0.7098\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.4467 Acc: 0.7973\n",
      "val Loss: 0.6277 Acc: 0.7115\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.4661 Acc: 0.7883\n",
      "val Loss: 0.6280 Acc: 0.7098\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.4516 Acc: 0.7988\n",
      "val Loss: 0.6279 Acc: 0.7098\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.4393 Acc: 0.8011\n",
      "val Loss: 0.6278 Acc: 0.7115\n",
      "\n",
      "Training complete in 3m 45s\n",
      "Best val Acc: 0.716783\n",
      "tensor(0.7168, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/squeezenet1_1.pth'\n",
    "model_ft = models.squeezenet1_1(pretrained=True,)\n",
    "# print(model_ft.classifier)\n",
    "model_ft.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "model_ft3 = models.squeezenet1_1(pretrained=True,)\n",
    "model_ft3.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb487805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.3416 Acc: 0.4204\n",
      "val Loss: 1.2709 Acc: 0.4161\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.1502 Acc: 0.4955\n",
      "val Loss: 1.0273 Acc: 0.6014\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.0566 Acc: 0.5428\n",
      "val Loss: 1.0320 Acc: 0.5822\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.9765 Acc: 0.5923\n",
      "val Loss: 0.8691 Acc: 0.6608\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.8510 Acc: 0.6539\n",
      "val Loss: 0.8693 Acc: 0.6836\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.7731 Acc: 0.6667\n",
      "val Loss: 0.6850 Acc: 0.7150\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.7185\n",
      "val Loss: 0.7365 Acc: 0.6976\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.5580 Acc: 0.7477\n",
      "val Loss: 0.6448 Acc: 0.7168\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.4875 Acc: 0.7860\n",
      "val Loss: 0.6495 Acc: 0.7290\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.4561 Acc: 0.7935\n",
      "val Loss: 0.6287 Acc: 0.7203\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.4421 Acc: 0.7950\n",
      "val Loss: 0.6388 Acc: 0.7290\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.4179 Acc: 0.8168\n",
      "val Loss: 0.6162 Acc: 0.7430\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.4010 Acc: 0.8213\n",
      "val Loss: 0.6545 Acc: 0.7185\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.3861 Acc: 0.8378\n",
      "val Loss: 0.6387 Acc: 0.7343\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.3535 Acc: 0.8491\n",
      "val Loss: 0.6332 Acc: 0.7308\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.3577 Acc: 0.8461\n",
      "val Loss: 0.6372 Acc: 0.7290\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.3629 Acc: 0.8438\n",
      "val Loss: 0.6388 Acc: 0.7220\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.3525 Acc: 0.8438\n",
      "val Loss: 0.6384 Acc: 0.7238\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.3422 Acc: 0.8619\n",
      "val Loss: 0.6399 Acc: 0.7238\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.3558 Acc: 0.8431\n",
      "val Loss: 0.6423 Acc: 0.7308\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.3512 Acc: 0.8483\n",
      "val Loss: 0.6418 Acc: 0.7343\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3477 Acc: 0.8468\n",
      "val Loss: 0.6413 Acc: 0.7325\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.3554 Acc: 0.8476\n",
      "val Loss: 0.6409 Acc: 0.7308\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.3393 Acc: 0.8619\n",
      "val Loss: 0.6409 Acc: 0.7325\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.3448 Acc: 0.8483\n",
      "val Loss: 0.6403 Acc: 0.7308\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.3490 Acc: 0.8461\n",
      "val Loss: 0.6403 Acc: 0.7308\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.3436 Acc: 0.8611\n",
      "val Loss: 0.6402 Acc: 0.7290\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.3470 Acc: 0.8529\n",
      "val Loss: 0.6402 Acc: 0.7290\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.3487 Acc: 0.8506\n",
      "val Loss: 0.6402 Acc: 0.7290\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.3446 Acc: 0.8581\n",
      "val Loss: 0.6402 Acc: 0.7290\n",
      "\n",
      "Training complete in 5m 17s\n",
      "Best val Acc: 0.743007\n",
      "tensor(0.7430, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/squeezenet1_0.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.squeezenet1_0(pretrained=True,)\n",
    "model_ft.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model_ft3 = models.squeezenet1_0(pretrained=True,)\n",
    "model_ft3.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d6dc5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.9763 Acc: 0.5743\n",
      "val Loss: 0.8787 Acc: 0.6259\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4473 Acc: 0.8138\n",
      "val Loss: 0.6059 Acc: 0.7133\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2923 Acc: 0.8889\n",
      "val Loss: 0.5872 Acc: 0.7535\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2104 Acc: 0.9174\n",
      "val Loss: 0.5084 Acc: 0.7902\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1460 Acc: 0.9467\n",
      "val Loss: 0.6511 Acc: 0.7815\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9655\n",
      "val Loss: 0.5427 Acc: 0.7972\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0682 Acc: 0.9827\n",
      "val Loss: 0.6127 Acc: 0.7955\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0416 Acc: 0.9880\n",
      "val Loss: 0.6177 Acc: 0.8112\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0463 Acc: 0.9880\n",
      "val Loss: 0.5846 Acc: 0.8059\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0346 Acc: 0.9940\n",
      "val Loss: 0.5738 Acc: 0.8077\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0335 Acc: 0.9925\n",
      "val Loss: 0.6326 Acc: 0.8129\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0305 Acc: 0.9947\n",
      "val Loss: 0.5964 Acc: 0.8164\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0241 Acc: 0.9970\n",
      "val Loss: 0.5973 Acc: 0.8094\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0271 Acc: 0.9962\n",
      "val Loss: 0.5815 Acc: 0.8059\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0246 Acc: 0.9962\n",
      "val Loss: 0.5930 Acc: 0.8059\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9985\n",
      "val Loss: 0.5933 Acc: 0.8059\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0242 Acc: 0.9970\n",
      "val Loss: 0.6243 Acc: 0.8094\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 0.9962\n",
      "val Loss: 0.5743 Acc: 0.8077\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0195 Acc: 0.9970\n",
      "val Loss: 0.5995 Acc: 0.8077\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.9977\n",
      "val Loss: 0.5915 Acc: 0.8042\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9940\n",
      "val Loss: 0.5958 Acc: 0.8024\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0246 Acc: 0.9947\n",
      "val Loss: 0.6248 Acc: 0.8007\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 0.9970\n",
      "val Loss: 0.5921 Acc: 0.8094\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9962\n",
      "val Loss: 0.6174 Acc: 0.8094\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0280 Acc: 0.9932\n",
      "val Loss: 0.5856 Acc: 0.8042\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 0.9955\n",
      "val Loss: 0.5779 Acc: 0.8077\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0248 Acc: 0.9962\n",
      "val Loss: 0.5788 Acc: 0.8094\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0200 Acc: 0.9985\n",
      "val Loss: 0.5755 Acc: 0.8059\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.9977\n",
      "val Loss: 0.5992 Acc: 0.8042\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0245 Acc: 0.9970\n",
      "val Loss: 0.6055 Acc: 0.8164\n",
      "\n",
      "Training complete in 56m 6s\n",
      "Best val Acc: 0.816434\n",
      "tensor(0.8164, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/densenet161.pth'\n",
    "\n",
    "# setup model\n",
    "model_ft = models.densenet161(pretrained=True,)\n",
    "model_ft.classifier=nn.Linear(2208,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train and save\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# laod model\n",
    "model_ft3 = models.densenet161(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(2208,len(classes))\n",
    "model_ft3.to(device)\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test model\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e40f6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1664, out_features=1000, bias=True)\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0045 Acc: 0.5608\n",
      "val Loss: 0.6471 Acc: 0.7098\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4806 Acc: 0.8026\n",
      "val Loss: 0.5425 Acc: 0.7570\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.3053 Acc: 0.8806\n",
      "val Loss: 0.5402 Acc: 0.7657\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2053 Acc: 0.9257\n",
      "val Loss: 0.4834 Acc: 0.7780\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1488 Acc: 0.9467\n",
      "val Loss: 0.6166 Acc: 0.7483\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1035 Acc: 0.9632\n",
      "val Loss: 0.6274 Acc: 0.7797\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0849 Acc: 0.9737\n",
      "val Loss: 0.5733 Acc: 0.7955\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0484 Acc: 0.9910\n",
      "val Loss: 0.6351 Acc: 0.8059\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0613 Acc: 0.9835\n",
      "val Loss: 0.6878 Acc: 0.7832\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0410 Acc: 0.9887\n",
      "val Loss: 0.6568 Acc: 0.8077\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 0.9932\n",
      "val Loss: 0.6153 Acc: 0.8059\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0369 Acc: 0.9932\n",
      "val Loss: 0.6228 Acc: 0.8024\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 0.9977\n",
      "val Loss: 0.6699 Acc: 0.7990\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.9940\n",
      "val Loss: 0.6143 Acc: 0.8164\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9970\n",
      "val Loss: 0.6585 Acc: 0.8059\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0277 Acc: 0.9955\n",
      "val Loss: 0.6386 Acc: 0.8147\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0280 Acc: 0.9955\n",
      "val Loss: 0.6596 Acc: 0.8077\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9955\n",
      "val Loss: 0.6277 Acc: 0.8129\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9955\n",
      "val Loss: 0.6284 Acc: 0.8077\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0333 Acc: 0.9947\n",
      "val Loss: 0.6416 Acc: 0.8129\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 0.9977\n",
      "val Loss: 0.6754 Acc: 0.8077\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0377 Acc: 0.9917\n",
      "val Loss: 0.6653 Acc: 0.8059\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0279 Acc: 0.9925\n",
      "val Loss: 0.6357 Acc: 0.8129\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.9970\n",
      "val Loss: 0.6468 Acc: 0.8077\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.9932\n",
      "val Loss: 0.6285 Acc: 0.8112\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0238 Acc: 0.9977\n",
      "val Loss: 0.6407 Acc: 0.8042\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9940\n",
      "val Loss: 0.6566 Acc: 0.8042\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9970\n",
      "val Loss: 0.6443 Acc: 0.8129\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9917\n",
      "val Loss: 0.6563 Acc: 0.8112\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0249 Acc: 0.9970\n",
      "val Loss: 0.6418 Acc: 0.8042\n",
      "\n",
      "Training complete in 26m 57s\n",
      "Best val Acc: 0.816434\n",
      "tensor(0.8164, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/densenet169.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.densenet169(pretrained=True,)\n",
    "print(model_ft.classifier)\n",
    "model_ft.classifier=nn.Linear(1664,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "#load\n",
    "model_ft3 = models.densenet169(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1664,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "#test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41e3617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0484 Acc: 0.5368\n",
      "val Loss: 0.7360 Acc: 0.6818\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.5011 Acc: 0.7793\n",
      "val Loss: 0.6185 Acc: 0.7360\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2902 Acc: 0.8821\n",
      "val Loss: 0.6155 Acc: 0.7500\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.1952 Acc: 0.9242\n",
      "val Loss: 0.5649 Acc: 0.7920\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1451 Acc: 0.9482\n",
      "val Loss: 0.5711 Acc: 0.7745\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1127 Acc: 0.9632\n",
      "val Loss: 0.5881 Acc: 0.7885\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0915 Acc: 0.9685\n",
      "val Loss: 0.6182 Acc: 0.7990\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0707 Acc: 0.9820\n",
      "val Loss: 0.6138 Acc: 0.7972\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0558 Acc: 0.9865\n",
      "val Loss: 0.6313 Acc: 0.7955\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0348 Acc: 0.9955\n",
      "val Loss: 0.6137 Acc: 0.7990\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0357 Acc: 0.9962\n",
      "val Loss: 0.6256 Acc: 0.7972\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.9955\n",
      "val Loss: 0.6374 Acc: 0.8042\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0389 Acc: 0.9917\n",
      "val Loss: 0.6370 Acc: 0.8007\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0380 Acc: 0.9917\n",
      "val Loss: 0.6402 Acc: 0.7867\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0288 Acc: 0.9970\n",
      "val Loss: 0.6249 Acc: 0.7937\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.9932\n",
      "val Loss: 0.6300 Acc: 0.7902\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9932\n",
      "val Loss: 0.6224 Acc: 0.7990\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0267 Acc: 0.9955\n",
      "val Loss: 0.6313 Acc: 0.7990\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0344 Acc: 0.9910\n",
      "val Loss: 0.6250 Acc: 0.7955\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0297 Acc: 0.9947\n",
      "val Loss: 0.6158 Acc: 0.7920\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0287 Acc: 0.9962\n",
      "val Loss: 0.6495 Acc: 0.7990\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0284 Acc: 0.9940\n",
      "val Loss: 0.6229 Acc: 0.7990\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0234 Acc: 0.9985\n",
      "val Loss: 0.6322 Acc: 0.8024\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0321 Acc: 0.9932\n",
      "val Loss: 0.6419 Acc: 0.7867\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0326 Acc: 0.9917\n",
      "val Loss: 0.6426 Acc: 0.7990\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0230 Acc: 0.9955\n",
      "val Loss: 0.6301 Acc: 0.7937\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0279 Acc: 0.9962\n",
      "val Loss: 0.6543 Acc: 0.7867\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9932\n",
      "val Loss: 0.6562 Acc: 0.7955\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0331 Acc: 0.9940\n",
      "val Loss: 0.6286 Acc: 0.7937\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0274 Acc: 0.9955\n",
      "val Loss: 0.6401 Acc: 0.7937\n",
      "\n",
      "Training complete in 20m 31s\n",
      "Best val Acc: 0.804196\n",
      "tensor(0.8042, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/densenet121.pth'\n",
    "model_ft = models.densenet121(pretrained=True,)\n",
    "model_ft.classifier=nn.Linear(1024,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "model_ft3 = models.densenet121(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1024,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa4a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
