{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b7ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from PIL import Image\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed20907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chickenpox', 'Measles', 'Monkeypox', 'Normal']\n",
      "{'Chickenpox': 0, 'Measles': 1, 'Monkeypox': 2, 'Normal': 3}\n"
     ]
    }
   ],
   "source": [
    "root = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/Data/'\n",
    "\n",
    "data_transform = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                     transforms.Resize((64,64)),\n",
    "                                     transforms.ToTensor()])\n",
    "dataset = ImageFolder(root, transform=data_transform)\n",
    "\n",
    "print(dataset.classes)\n",
    "print(dataset.class_to_idx)\n",
    "\n",
    "# Split test and train dataset \n",
    "train_size = int(0.7 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_data, test_data = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Set batch size of train data loader\n",
    "batch_size_train = 20\n",
    "\n",
    "# Set batch size of test data loader\n",
    "batch_size_test = 22\n",
    "\n",
    "# load the split train and test data into batches via DataLoader()\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "label_map={\n",
    "    0:\"Chickenpox\",\n",
    "    1:\"Measles\",\n",
    "    2:\"Monkeypox\",\n",
    "    3:\"Normal\"\n",
    "}\n",
    "classes = ('Chickenpox', 'Measles', 'Monkeypox', 'Normal')\n",
    "\n",
    "dataloaders={}\n",
    "dataloaders[\"train\"]=train_loader\n",
    "dataloaders[\"val\"]=test_loader\n",
    "\n",
    "dataset_sizes = {\"train\":len(train_loader.dataset),\"val\":len(test_loader.dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9c1316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Normal')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    pass\n",
    "\n",
    "# Get one batch\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "indx=10\n",
    "plt.imshow(images[indx].reshape(64,64))\n",
    "plt.title(label_map[int(labels[indx].numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1478a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs=30\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.repeat(1, 3, 1, 1)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy(model, test_loader) :\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_corrects=0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.repeat(1, 3, 1, 1)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device) \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        acc = running_corrects.double() / dataset_sizes[\"val\"]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0771f5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Counter({2: 442, 3: 417, 0: 260, 1: 213})\n",
      "Test: Counter({2: 188, 3: 168, 0: 116, 1: 100})\n",
      "Total: {0: 376, 1: 313, 2: 630, 3: 585}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_classes = [dataset.targets[i] for i in train_data.indices]\n",
    "print(\"train:\",Counter(train_classes)) # if doesn' work: Counter(i.item() for i in train_classes)\n",
    "\n",
    "test_classes = [dataset.targets[i] for i in test_data.indices]\n",
    "print(\"Test:\",Counter(test_classes)) # if doesn' work: Counter(i.item() for i in train_classes)\n",
    "\n",
    "print(\"Total:\",dict(Counter(test_data.dataset.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cdaa5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sajan\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0662 Acc: 0.5488\n",
      "val Loss: 0.8768 Acc: 0.6521\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.5128 Acc: 0.7913\n",
      "val Loss: 0.8482 Acc: 0.6469\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2966 Acc: 0.8799\n",
      "val Loss: 0.6631 Acc: 0.7360\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.1879 Acc: 0.9317\n",
      "val Loss: 0.6647 Acc: 0.7255\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1540 Acc: 0.9392\n",
      "val Loss: 0.7359 Acc: 0.7483\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1367 Acc: 0.9542\n",
      "val Loss: 0.7342 Acc: 0.7255\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0936 Acc: 0.9722\n",
      "val Loss: 0.7042 Acc: 0.7692\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0588 Acc: 0.9835\n",
      "val Loss: 0.7004 Acc: 0.7640\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.9880\n",
      "val Loss: 0.6815 Acc: 0.7762\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0478 Acc: 0.9895\n",
      "val Loss: 0.6638 Acc: 0.7815\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0461 Acc: 0.9887\n",
      "val Loss: 0.7085 Acc: 0.7745\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0348 Acc: 0.9962\n",
      "val Loss: 0.6913 Acc: 0.7762\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0398 Acc: 0.9932\n",
      "val Loss: 0.7113 Acc: 0.7780\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0277 Acc: 0.9962\n",
      "val Loss: 0.7020 Acc: 0.7622\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.9962\n",
      "val Loss: 0.7213 Acc: 0.7710\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9970\n",
      "val Loss: 0.7057 Acc: 0.7797\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0322 Acc: 0.9947\n",
      "val Loss: 0.7169 Acc: 0.7692\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0381 Acc: 0.9910\n",
      "val Loss: 0.7125 Acc: 0.7762\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0335 Acc: 0.9940\n",
      "val Loss: 0.7383 Acc: 0.7657\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0246 Acc: 0.9977\n",
      "val Loss: 0.7249 Acc: 0.7797\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0277 Acc: 0.9970\n",
      "val Loss: 0.7121 Acc: 0.7745\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0288 Acc: 0.9947\n",
      "val Loss: 0.7137 Acc: 0.7745\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0249 Acc: 0.9985\n",
      "val Loss: 0.7158 Acc: 0.7797\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0372 Acc: 0.9932\n",
      "val Loss: 0.7382 Acc: 0.7710\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9947\n",
      "val Loss: 0.7285 Acc: 0.7640\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0323 Acc: 0.9962\n",
      "val Loss: 0.7210 Acc: 0.7815\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0322 Acc: 0.9925\n",
      "val Loss: 0.7165 Acc: 0.7727\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0297 Acc: 0.9940\n",
      "val Loss: 0.7105 Acc: 0.7710\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.9970\n",
      "val Loss: 0.7235 Acc: 0.7727\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0346 Acc: 0.9947\n",
      "val Loss: 0.7376 Acc: 0.7727\n",
      "\n",
      "Training complete in 12m 25s\n",
      "Best val Acc: 0.781469\n",
      "tensor(0.7815, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/resnet18_net.pth'\n",
    "\n",
    "#setup model\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# training\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load model\n",
    "model_ft3 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft3.fc.in_features\n",
    "model_ft3.fc = nn.Linear(num_ftrs, len(classes))\n",
    "model_ft3.to(device)\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test accuracy\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7404a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.2824 Acc: 0.4332\n",
      "val Loss: 1.0927 Acc: 0.4808\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.0099 Acc: 0.5526\n",
      "val Loss: 0.9830 Acc: 0.5647\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.8549 Acc: 0.6291\n",
      "val Loss: 0.9054 Acc: 0.6224\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.7222 Acc: 0.6892\n",
      "val Loss: 0.9580 Acc: 0.5769\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.6267 Acc: 0.7432\n",
      "val Loss: 0.7481 Acc: 0.6696\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.5724 Acc: 0.7470\n",
      "val Loss: 0.8213 Acc: 0.6311\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.4645 Acc: 0.8063\n",
      "val Loss: 0.6847 Acc: 0.6958\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.3023 Acc: 0.8739\n",
      "val Loss: 0.6709 Acc: 0.7168\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.2574 Acc: 0.8934\n",
      "val Loss: 0.6512 Acc: 0.7220\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.2384 Acc: 0.9024\n",
      "val Loss: 0.6667 Acc: 0.7185\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.2212 Acc: 0.9099\n",
      "val Loss: 0.6611 Acc: 0.7098\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.2091 Acc: 0.9249\n",
      "val Loss: 0.6498 Acc: 0.7255\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.1929 Acc: 0.9279\n",
      "val Loss: 0.6677 Acc: 0.7168\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.1844 Acc: 0.9362\n",
      "val Loss: 0.6573 Acc: 0.7220\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.1694 Acc: 0.9399\n",
      "val Loss: 0.6601 Acc: 0.7238\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.1698 Acc: 0.9407\n",
      "val Loss: 0.6631 Acc: 0.7238\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.1723 Acc: 0.9332\n",
      "val Loss: 0.6633 Acc: 0.7238\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.1652 Acc: 0.9497\n",
      "val Loss: 0.6653 Acc: 0.7203\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.1675 Acc: 0.9384\n",
      "val Loss: 0.6679 Acc: 0.7203\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.1680 Acc: 0.9392\n",
      "val Loss: 0.6696 Acc: 0.7220\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.1607 Acc: 0.9467\n",
      "val Loss: 0.6702 Acc: 0.7238\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.1601 Acc: 0.9482\n",
      "val Loss: 0.6702 Acc: 0.7255\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.1609 Acc: 0.9444\n",
      "val Loss: 0.6702 Acc: 0.7220\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.1611 Acc: 0.9452\n",
      "val Loss: 0.6704 Acc: 0.7238\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.1596 Acc: 0.9512\n",
      "val Loss: 0.6704 Acc: 0.7220\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.1593 Acc: 0.9512\n",
      "val Loss: 0.6702 Acc: 0.7220\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.1587 Acc: 0.9452\n",
      "val Loss: 0.6702 Acc: 0.7203\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.1592 Acc: 0.9467\n",
      "val Loss: 0.6703 Acc: 0.7203\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.1658 Acc: 0.9422\n",
      "val Loss: 0.6703 Acc: 0.7203\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.1608 Acc: 0.9474\n",
      "val Loss: 0.6703 Acc: 0.7203\n",
      "\n",
      "Training complete in 15m 55s\n",
      "Best val Acc: 0.725524\n",
      "tensor(0.7255, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/alex_net.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.alexnet(pretrained=True,)\n",
    "model_ft.classifier[6] = nn.Linear(4096,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model_ft3 = models.alexnet(pretrained=True)\n",
    "model_ft3.classifier[6] = nn.Linear(4096,len(classes))\n",
    "model_ft3.to(device)\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3504b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet201_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet201_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.9963 Acc: 0.5758\n",
      "val Loss: 0.8728 Acc: 0.6451\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4878 Acc: 0.7890\n",
      "val Loss: 0.5871 Acc: 0.7622\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2824 Acc: 0.8941\n",
      "val Loss: 0.6163 Acc: 0.7500\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2028 Acc: 0.9294\n",
      "val Loss: 0.5749 Acc: 0.7867\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1328 Acc: 0.9520\n",
      "val Loss: 0.5602 Acc: 0.8007\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.0986 Acc: 0.9647\n",
      "val Loss: 0.5678 Acc: 0.7972\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0748 Acc: 0.9790\n",
      "val Loss: 0.6014 Acc: 0.7815\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0503 Acc: 0.9887\n",
      "val Loss: 0.5682 Acc: 0.8059\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0437 Acc: 0.9902\n",
      "val Loss: 0.5654 Acc: 0.8164\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0353 Acc: 0.9940\n",
      "val Loss: 0.5646 Acc: 0.8164\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0281 Acc: 0.9977\n",
      "val Loss: 0.5740 Acc: 0.8129\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9947\n",
      "val Loss: 0.5817 Acc: 0.8077\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9947\n",
      "val Loss: 0.5749 Acc: 0.8182\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.9940\n",
      "val Loss: 0.5702 Acc: 0.8269\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.9955\n",
      "val Loss: 0.5751 Acc: 0.8234\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0273 Acc: 0.9947\n",
      "val Loss: 0.5742 Acc: 0.8322\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 0.9985\n",
      "val Loss: 0.5800 Acc: 0.8269\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0265 Acc: 0.9955\n",
      "val Loss: 0.5849 Acc: 0.8129\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9985\n",
      "val Loss: 0.5899 Acc: 0.8147\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0270 Acc: 0.9955\n",
      "val Loss: 0.5877 Acc: 0.8147\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0190 Acc: 0.9992\n",
      "val Loss: 0.5764 Acc: 0.8182\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0206 Acc: 1.0000\n",
      "val Loss: 0.5697 Acc: 0.8217\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9940\n",
      "val Loss: 0.5863 Acc: 0.8129\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0329 Acc: 0.9962\n",
      "val Loss: 0.5665 Acc: 0.8304\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0245 Acc: 0.9962\n",
      "val Loss: 0.5758 Acc: 0.8269\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0258 Acc: 0.9977\n",
      "val Loss: 0.5664 Acc: 0.8269\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0298 Acc: 0.9955\n",
      "val Loss: 0.5894 Acc: 0.8269\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0281 Acc: 0.9940\n",
      "val Loss: 0.5967 Acc: 0.8199\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.9962\n",
      "val Loss: 0.5835 Acc: 0.8269\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0260 Acc: 0.9940\n",
      "val Loss: 0.5731 Acc: 0.8269\n",
      "\n",
      "Training complete in 39m 25s\n",
      "Best val Acc: 0.832168\n",
      "tensor(0.8322, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/densenet201.pth'\n",
    "model_ft = models.densenet201(pretrained=True,)\n",
    "# print(model_ft.classifier)\n",
    "model_ft.classifier=nn.Linear(1920,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "model_ft3 = models.densenet201(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1920,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0664fb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=SqueezeNet1_1_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_1_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.4030 Acc: 0.3581\n",
      "val Loss: 1.2296 Acc: 0.4755\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.2049 Acc: 0.4827\n",
      "val Loss: 1.1060 Acc: 0.5612\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.1538 Acc: 0.5098\n",
      "val Loss: 1.0824 Acc: 0.5437\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 1.0582 Acc: 0.5353\n",
      "val Loss: 1.0178 Acc: 0.5594\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.9627 Acc: 0.5961\n",
      "val Loss: 0.8460 Acc: 0.6573\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.8596 Acc: 0.6284\n",
      "val Loss: 0.8022 Acc: 0.6678\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.7705 Acc: 0.6494\n",
      "val Loss: 0.7540 Acc: 0.6906\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.6367 Acc: 0.7102\n",
      "val Loss: 0.7057 Acc: 0.6801\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.5838 Acc: 0.7372\n",
      "val Loss: 0.6867 Acc: 0.6748\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.5530 Acc: 0.7410\n",
      "val Loss: 0.6750 Acc: 0.6766\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.5509 Acc: 0.7568\n",
      "val Loss: 0.6780 Acc: 0.6941\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.5355 Acc: 0.7688\n",
      "val Loss: 0.6457 Acc: 0.6958\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.5016 Acc: 0.7793\n",
      "val Loss: 0.6359 Acc: 0.7028\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.4851 Acc: 0.7815\n",
      "val Loss: 0.6362 Acc: 0.6993\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.4538 Acc: 0.7988\n",
      "val Loss: 0.6357 Acc: 0.7045\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.4624 Acc: 0.7973\n",
      "val Loss: 0.6331 Acc: 0.7028\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.4496 Acc: 0.8086\n",
      "val Loss: 0.6303 Acc: 0.7045\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.4646 Acc: 0.7890\n",
      "val Loss: 0.6282 Acc: 0.7063\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.4645 Acc: 0.7920\n",
      "val Loss: 0.6275 Acc: 0.7168\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.4593 Acc: 0.7965\n",
      "val Loss: 0.6275 Acc: 0.7080\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.4548 Acc: 0.7853\n",
      "val Loss: 0.6271 Acc: 0.7045\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.4529 Acc: 0.7935\n",
      "val Loss: 0.6263 Acc: 0.7045\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.4473 Acc: 0.7980\n",
      "val Loss: 0.6263 Acc: 0.7080\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.4574 Acc: 0.7920\n",
      "val Loss: 0.6271 Acc: 0.7115\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.4358 Acc: 0.7988\n",
      "val Loss: 0.6266 Acc: 0.7115\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.4536 Acc: 0.7965\n",
      "val Loss: 0.6273 Acc: 0.7098\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.4467 Acc: 0.7973\n",
      "val Loss: 0.6277 Acc: 0.7115\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.4661 Acc: 0.7883\n",
      "val Loss: 0.6280 Acc: 0.7098\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.4516 Acc: 0.7988\n",
      "val Loss: 0.6279 Acc: 0.7098\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.4393 Acc: 0.8011\n",
      "val Loss: 0.6278 Acc: 0.7115\n",
      "\n",
      "Training complete in 3m 45s\n",
      "Best val Acc: 0.716783\n",
      "tensor(0.7168, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/squeezenet1_1.pth'\n",
    "model_ft = models.squeezenet1_1(pretrained=True,)\n",
    "# print(model_ft.classifier)\n",
    "model_ft.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "model_ft3 = models.squeezenet1_1(pretrained=True,)\n",
    "model_ft3.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb487805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=SqueezeNet1_0_Weights.IMAGENET1K_V1`. You can also use `weights=SqueezeNet1_0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.3416 Acc: 0.4204\n",
      "val Loss: 1.2709 Acc: 0.4161\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 1.1502 Acc: 0.4955\n",
      "val Loss: 1.0273 Acc: 0.6014\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 1.0566 Acc: 0.5428\n",
      "val Loss: 1.0320 Acc: 0.5822\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.9765 Acc: 0.5923\n",
      "val Loss: 0.8691 Acc: 0.6608\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.8510 Acc: 0.6539\n",
      "val Loss: 0.8693 Acc: 0.6836\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.7731 Acc: 0.6667\n",
      "val Loss: 0.6850 Acc: 0.7150\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.7185\n",
      "val Loss: 0.7365 Acc: 0.6976\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.5580 Acc: 0.7477\n",
      "val Loss: 0.6448 Acc: 0.7168\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.4875 Acc: 0.7860\n",
      "val Loss: 0.6495 Acc: 0.7290\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.4561 Acc: 0.7935\n",
      "val Loss: 0.6287 Acc: 0.7203\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.4421 Acc: 0.7950\n",
      "val Loss: 0.6388 Acc: 0.7290\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.4179 Acc: 0.8168\n",
      "val Loss: 0.6162 Acc: 0.7430\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.4010 Acc: 0.8213\n",
      "val Loss: 0.6545 Acc: 0.7185\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.3861 Acc: 0.8378\n",
      "val Loss: 0.6387 Acc: 0.7343\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.3535 Acc: 0.8491\n",
      "val Loss: 0.6332 Acc: 0.7308\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.3577 Acc: 0.8461\n",
      "val Loss: 0.6372 Acc: 0.7290\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.3629 Acc: 0.8438\n",
      "val Loss: 0.6388 Acc: 0.7220\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.3525 Acc: 0.8438\n",
      "val Loss: 0.6384 Acc: 0.7238\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.3422 Acc: 0.8619\n",
      "val Loss: 0.6399 Acc: 0.7238\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.3558 Acc: 0.8431\n",
      "val Loss: 0.6423 Acc: 0.7308\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.3512 Acc: 0.8483\n",
      "val Loss: 0.6418 Acc: 0.7343\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.3477 Acc: 0.8468\n",
      "val Loss: 0.6413 Acc: 0.7325\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.3554 Acc: 0.8476\n",
      "val Loss: 0.6409 Acc: 0.7308\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.3393 Acc: 0.8619\n",
      "val Loss: 0.6409 Acc: 0.7325\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.3448 Acc: 0.8483\n",
      "val Loss: 0.6403 Acc: 0.7308\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.3490 Acc: 0.8461\n",
      "val Loss: 0.6403 Acc: 0.7308\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.3436 Acc: 0.8611\n",
      "val Loss: 0.6402 Acc: 0.7290\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.3470 Acc: 0.8529\n",
      "val Loss: 0.6402 Acc: 0.7290\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.3487 Acc: 0.8506\n",
      "val Loss: 0.6402 Acc: 0.7290\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.3446 Acc: 0.8581\n",
      "val Loss: 0.6402 Acc: 0.7290\n",
      "\n",
      "Training complete in 5m 17s\n",
      "Best val Acc: 0.743007\n",
      "tensor(0.7430, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/squeezenet1_0.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.squeezenet1_0(pretrained=True,)\n",
    "model_ft.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# load\n",
    "model_ft3 = models.squeezenet1_0(pretrained=True,)\n",
    "model_ft3.classifier[1] = nn.Conv2d(512, len(classes), kernel_size=(1,1), stride=(1,1))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d6dc5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet161_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet161_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 0.9763 Acc: 0.5743\n",
      "val Loss: 0.8787 Acc: 0.6259\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4473 Acc: 0.8138\n",
      "val Loss: 0.6059 Acc: 0.7133\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2923 Acc: 0.8889\n",
      "val Loss: 0.5872 Acc: 0.7535\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2104 Acc: 0.9174\n",
      "val Loss: 0.5084 Acc: 0.7902\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1460 Acc: 0.9467\n",
      "val Loss: 0.6511 Acc: 0.7815\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1004 Acc: 0.9655\n",
      "val Loss: 0.5427 Acc: 0.7972\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0682 Acc: 0.9827\n",
      "val Loss: 0.6127 Acc: 0.7955\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0416 Acc: 0.9880\n",
      "val Loss: 0.6177 Acc: 0.8112\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0463 Acc: 0.9880\n",
      "val Loss: 0.5846 Acc: 0.8059\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0346 Acc: 0.9940\n",
      "val Loss: 0.5738 Acc: 0.8077\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0335 Acc: 0.9925\n",
      "val Loss: 0.6326 Acc: 0.8129\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0305 Acc: 0.9947\n",
      "val Loss: 0.5964 Acc: 0.8164\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0241 Acc: 0.9970\n",
      "val Loss: 0.5973 Acc: 0.8094\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0271 Acc: 0.9962\n",
      "val Loss: 0.5815 Acc: 0.8059\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0246 Acc: 0.9962\n",
      "val Loss: 0.5930 Acc: 0.8059\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9985\n",
      "val Loss: 0.5933 Acc: 0.8059\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0242 Acc: 0.9970\n",
      "val Loss: 0.6243 Acc: 0.8094\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0240 Acc: 0.9962\n",
      "val Loss: 0.5743 Acc: 0.8077\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0195 Acc: 0.9970\n",
      "val Loss: 0.5995 Acc: 0.8077\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0212 Acc: 0.9977\n",
      "val Loss: 0.5915 Acc: 0.8042\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9940\n",
      "val Loss: 0.5958 Acc: 0.8024\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0246 Acc: 0.9947\n",
      "val Loss: 0.6248 Acc: 0.8007\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 0.9970\n",
      "val Loss: 0.5921 Acc: 0.8094\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0220 Acc: 0.9962\n",
      "val Loss: 0.6174 Acc: 0.8094\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0280 Acc: 0.9932\n",
      "val Loss: 0.5856 Acc: 0.8042\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 0.9955\n",
      "val Loss: 0.5779 Acc: 0.8077\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0248 Acc: 0.9962\n",
      "val Loss: 0.5788 Acc: 0.8094\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0200 Acc: 0.9985\n",
      "val Loss: 0.5755 Acc: 0.8059\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0213 Acc: 0.9977\n",
      "val Loss: 0.5992 Acc: 0.8042\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0245 Acc: 0.9970\n",
      "val Loss: 0.6055 Acc: 0.8164\n",
      "\n",
      "Training complete in 56m 6s\n",
      "Best val Acc: 0.816434\n",
      "tensor(0.8164, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/densenet161.pth'\n",
    "\n",
    "# setup model\n",
    "model_ft = models.densenet161(pretrained=True,)\n",
    "model_ft.classifier=nn.Linear(2208,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train and save\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "# laod model\n",
    "model_ft3 = models.densenet161(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(2208,len(classes))\n",
    "model_ft3.to(device)\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "# test model\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e40f6009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1664, out_features=1000, bias=True)\n",
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0045 Acc: 0.5608\n",
      "val Loss: 0.6471 Acc: 0.7098\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.4806 Acc: 0.8026\n",
      "val Loss: 0.5425 Acc: 0.7570\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.3053 Acc: 0.8806\n",
      "val Loss: 0.5402 Acc: 0.7657\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.2053 Acc: 0.9257\n",
      "val Loss: 0.4834 Acc: 0.7780\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1488 Acc: 0.9467\n",
      "val Loss: 0.6166 Acc: 0.7483\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1035 Acc: 0.9632\n",
      "val Loss: 0.6274 Acc: 0.7797\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0849 Acc: 0.9737\n",
      "val Loss: 0.5733 Acc: 0.7955\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0484 Acc: 0.9910\n",
      "val Loss: 0.6351 Acc: 0.8059\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0613 Acc: 0.9835\n",
      "val Loss: 0.6878 Acc: 0.7832\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0410 Acc: 0.9887\n",
      "val Loss: 0.6568 Acc: 0.8077\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0434 Acc: 0.9932\n",
      "val Loss: 0.6153 Acc: 0.8059\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0369 Acc: 0.9932\n",
      "val Loss: 0.6228 Acc: 0.8024\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0266 Acc: 0.9977\n",
      "val Loss: 0.6699 Acc: 0.7990\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0319 Acc: 0.9940\n",
      "val Loss: 0.6143 Acc: 0.8164\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9970\n",
      "val Loss: 0.6585 Acc: 0.8059\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0277 Acc: 0.9955\n",
      "val Loss: 0.6386 Acc: 0.8147\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0280 Acc: 0.9955\n",
      "val Loss: 0.6596 Acc: 0.8077\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9955\n",
      "val Loss: 0.6277 Acc: 0.8129\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9955\n",
      "val Loss: 0.6284 Acc: 0.8077\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0333 Acc: 0.9947\n",
      "val Loss: 0.6416 Acc: 0.8129\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0236 Acc: 0.9977\n",
      "val Loss: 0.6754 Acc: 0.8077\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0377 Acc: 0.9917\n",
      "val Loss: 0.6653 Acc: 0.8059\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0279 Acc: 0.9925\n",
      "val Loss: 0.6357 Acc: 0.8129\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0300 Acc: 0.9970\n",
      "val Loss: 0.6468 Acc: 0.8077\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0301 Acc: 0.9932\n",
      "val Loss: 0.6285 Acc: 0.8112\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0238 Acc: 0.9977\n",
      "val Loss: 0.6407 Acc: 0.8042\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9940\n",
      "val Loss: 0.6566 Acc: 0.8042\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9970\n",
      "val Loss: 0.6443 Acc: 0.8129\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0338 Acc: 0.9917\n",
      "val Loss: 0.6563 Acc: 0.8112\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0249 Acc: 0.9970\n",
      "val Loss: 0.6418 Acc: 0.8042\n",
      "\n",
      "Training complete in 26m 57s\n",
      "Best val Acc: 0.816434\n",
      "tensor(0.8164, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/densenet169.pth'\n",
    "\n",
    "# setup\n",
    "model_ft = models.densenet169(pretrained=True,)\n",
    "print(model_ft.classifier)\n",
    "model_ft.classifier=nn.Linear(1664,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "# train\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "\n",
    "#load\n",
    "model_ft3 = models.densenet169(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1664,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "\n",
    "#test\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41e3617b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajan\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/29\n",
      "----------\n",
      "train Loss: 1.0484 Acc: 0.5368\n",
      "val Loss: 0.7360 Acc: 0.6818\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train Loss: 0.5011 Acc: 0.7793\n",
      "val Loss: 0.6185 Acc: 0.7360\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train Loss: 0.2902 Acc: 0.8821\n",
      "val Loss: 0.6155 Acc: 0.7500\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train Loss: 0.1952 Acc: 0.9242\n",
      "val Loss: 0.5649 Acc: 0.7920\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train Loss: 0.1451 Acc: 0.9482\n",
      "val Loss: 0.5711 Acc: 0.7745\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train Loss: 0.1127 Acc: 0.9632\n",
      "val Loss: 0.5881 Acc: 0.7885\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train Loss: 0.0915 Acc: 0.9685\n",
      "val Loss: 0.6182 Acc: 0.7990\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train Loss: 0.0707 Acc: 0.9820\n",
      "val Loss: 0.6138 Acc: 0.7972\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train Loss: 0.0558 Acc: 0.9865\n",
      "val Loss: 0.6313 Acc: 0.7955\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train Loss: 0.0348 Acc: 0.9955\n",
      "val Loss: 0.6137 Acc: 0.7990\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train Loss: 0.0357 Acc: 0.9962\n",
      "val Loss: 0.6256 Acc: 0.7972\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train Loss: 0.0311 Acc: 0.9955\n",
      "val Loss: 0.6374 Acc: 0.8042\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train Loss: 0.0389 Acc: 0.9917\n",
      "val Loss: 0.6370 Acc: 0.8007\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train Loss: 0.0380 Acc: 0.9917\n",
      "val Loss: 0.6402 Acc: 0.7867\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train Loss: 0.0288 Acc: 0.9970\n",
      "val Loss: 0.6249 Acc: 0.7937\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train Loss: 0.0309 Acc: 0.9932\n",
      "val Loss: 0.6300 Acc: 0.7902\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train Loss: 0.0302 Acc: 0.9932\n",
      "val Loss: 0.6224 Acc: 0.7990\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train Loss: 0.0267 Acc: 0.9955\n",
      "val Loss: 0.6313 Acc: 0.7990\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train Loss: 0.0344 Acc: 0.9910\n",
      "val Loss: 0.6250 Acc: 0.7955\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train Loss: 0.0297 Acc: 0.9947\n",
      "val Loss: 0.6158 Acc: 0.7920\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train Loss: 0.0287 Acc: 0.9962\n",
      "val Loss: 0.6495 Acc: 0.7990\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train Loss: 0.0284 Acc: 0.9940\n",
      "val Loss: 0.6229 Acc: 0.7990\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train Loss: 0.0234 Acc: 0.9985\n",
      "val Loss: 0.6322 Acc: 0.8024\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train Loss: 0.0321 Acc: 0.9932\n",
      "val Loss: 0.6419 Acc: 0.7867\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train Loss: 0.0326 Acc: 0.9917\n",
      "val Loss: 0.6426 Acc: 0.7990\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train Loss: 0.0230 Acc: 0.9955\n",
      "val Loss: 0.6301 Acc: 0.7937\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train Loss: 0.0279 Acc: 0.9962\n",
      "val Loss: 0.6543 Acc: 0.7867\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train Loss: 0.0291 Acc: 0.9932\n",
      "val Loss: 0.6562 Acc: 0.7955\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train Loss: 0.0331 Acc: 0.9940\n",
      "val Loss: 0.6286 Acc: 0.7937\n",
      "\n",
      "Epoch 29/29\n",
      "----------\n",
      "train Loss: 0.0274 Acc: 0.9955\n",
      "val Loss: 0.6401 Acc: 0.7937\n",
      "\n",
      "Training complete in 20m 31s\n",
      "Best val Acc: 0.804196\n",
      "tensor(0.8042, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "PATH = 'C:/Users/sajan/OneDrive/Desktop/Main Project/Project/densenet121.pth'\n",
    "model_ft = models.densenet121(pretrained=True,)\n",
    "model_ft.classifier=nn.Linear(1024,len(classes))\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=num_epochs)\n",
    "\n",
    "torch.save(model_ft.state_dict(), PATH)\n",
    "model_ft3 = models.densenet121(pretrained=True)\n",
    "model_ft3.classifier=nn.Linear(1024,len(classes))\n",
    "model_ft3.to(device)\n",
    "\n",
    "model_ft3.load_state_dict(torch.load(PATH,map_location=device))\n",
    "model_ft3.eval()\n",
    "print(accuracy(model_ft3, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aa4a28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
